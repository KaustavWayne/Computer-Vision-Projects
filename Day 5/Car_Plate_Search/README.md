# ğŸš— Car Number Plate Detection & Search

![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![YOLO](https://img.shields.io/badge/YOLO-Ultralytics-red)
![Streamlit](https://img.shields.io/badge/Streamlit-App-ff4b4b)
![OpenCV](https://img.shields.io/badge/OpenCV-Computer%20Vision-green)
![License](https://img.shields.io/badge/License-MIT-yellow)

A **YOLO-based Car Number Plate Detection system** with an interactive **Streamlit UI** that allows users to:

- Run inference on image directories or uploaded images  
- Save & reload inference metadata  
- Search and visualize detected plates  
- Display bounding boxes with confidence scores  

---

## ğŸ“Œ Project Features

- ğŸ” YOLO-based number plate detection  
- ğŸ–¼ï¸ Directory-based & upload-based inference  
- ğŸ“¦ Metadata generation (`metadata.json`)  
- ğŸ” Search-driven visualization (no auto-render)  
- ğŸ“Š Adjustable grid layout  
- ğŸ¨ Styled Streamlit UI  
- ğŸ’¾ Reusable inference results  

---

## ğŸ§  High-Level Workflow

(Training â†’ Inference â†’ Metadata Generation â†’ Search & Visualization via Streamlit)

---

## ğŸ“ Project Structure

```text
car_number_plate_detection/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best.pt
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ uploads/
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ detector.py
    â”œâ”€â”€ metadata.py
    â””â”€â”€ utils.py
```

---

## ğŸ—‚ï¸ Dataset

- Source: **Roboflow**
- Format: **YOLOv8**
- Class: `number_plate`

You should download the dataset in **YOLO format**.

---

## ğŸ§ª Model Training (Google Colab)

### Steps

1. Upload dataset ZIP to Google Drive  
2. Mount Drive  
3. Train YOLO model  
4. Save `best.pt` back to Drive  

```python
from google.colab import drive
drive.mount('/content/drive')
```

```bash
pip install ultralytics
```

```python
from ultralytics import YOLO

model = YOLO("yolov8n.pt")
model.train(
    data="data.yaml",
    epochs=50,
    imgsz=640
)
```

Download the trained weights from:

```text
runs/detect/train/weights/best.pt
```

---

## ğŸ’» Local Setup (VS Code)

### 1ï¸âƒ£ Create environment

```bash
conda create -n plate python=3.9
conda activate plate
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Add trained model

Place your trained weights at:

```text
models/best.pt
```

---

## â–¶ï¸ Run Streamlit App

```bash
streamlit run app.py
```

---

## ğŸ–¥ï¸ Streamlit Usage

### Option 1: Process New Images

- Load from directory path **or** upload new images  
- Click **Run Inference**

You will see a message like:

> Successfully processed X images

---

### Option 2: Search Images

- Click **Search Images**  
- View detected plates with bounding boxes  

---

### Option 3: Load Existing Metadata

- Upload `metadata.json`  
- Instantly visualize previous results  

---

## ğŸ“Š Metadata Format (`metadata.json`)

```json
{
  "image_path.jpg": {
    "plate_count": 1,
    "detections": [[x1, y1, x2, y2, 0.82]]
  }
}
```

---

## ğŸ§  Technologies Used

- Python  
- YOLO (Ultralytics)  
- OpenCV  
- Streamlit  
- Roboflow  
- Google Colab  

---

## ğŸ¯ Interview Talking Point

> â€œI built a modular computer vision pipeline separating training, inference, metadata persistence, and search-based visualization using Streamlit.â€

---

## ğŸš€ Future Improvements

- OCR for number plate text extraction  
- Video & webcam inference  
- Confidence threshold slider  
- Deployment on Streamlit Cloud  

---

## ğŸ“œ License

**MIT License**

---

## âœ… WHAT YOU NOW HAVE

âœ” Professional README  
âœ” Shields.io badges  
âœ” Clear workflow  
âœ” Project template  
âœ” Interview-ready documentation  

---

